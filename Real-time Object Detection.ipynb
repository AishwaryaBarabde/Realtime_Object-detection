{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b7b47a8a",
      "metadata": {
        "id": "b7b47a8a"
      },
      "source": [
        "# Real-Time Object Detection using YOLOv8 (pretrained COCO)\n",
        "\n",
        "**Author:** Aishwarya\n",
        "\n",
        "This Colab-ready notebook demonstrates quick setup and real-time inference using a pretrained YOLOv8 model (COCO). It's beginner-friendly and ideal for live demos.\n",
        "\n",
        "---\n",
        "\n",
        "Contents:\n",
        "1. Setup\n",
        "2. Load pretrained model\n",
        "3. Inference on images/videos\n",
        "4. Real-time webcam usage (local)\n",
        "5. Tips for filtering classes and saving outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68818e9b",
      "metadata": {
        "id": "68818e9b"
      },
      "source": [
        "## 1) Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0222086e",
      "metadata": {
        "id": "0222086e",
        "outputId": "6cead1bc-3b18-43fa-c224-04ce09e84095",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Setup complete\n"
          ]
        }
      ],
      "source": [
        "!pip install -q ultralytics opencv-python-headless\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2, time, os\n",
        "print('Setup complete')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "825096c6",
      "metadata": {
        "id": "825096c6"
      },
      "source": [
        "## 2) Load pretrained YOLOv8 model\n",
        "\n",
        "We'll use `yolov8n.pt` (nano) for speed. It contains COCO classes by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81acd64e",
      "metadata": {
        "id": "81acd64e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79af3986-c539-47d6-b232-84bb7d8ea889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 75.3MB/s 0.1s\n",
            "Model loaded. Number of classes: 80\n",
            "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n.pt')\n",
        "print('Model loaded. Number of classes:', len(model.names))\n",
        "print(model.names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "195d273e",
      "metadata": {
        "id": "195d273e"
      },
      "source": [
        "## 3) Inference on an image\n",
        "\n",
        "Upload an image to the Colab session (left sidebar) or provide a path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b427ffb",
      "metadata": {
        "id": "2b427ffb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6999f613-1194-47c4-f1dc-58b80dae3d23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload an image named bus.jpg via the Colab file browser or change the path.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sample_img = '/content/Bus.png'  # replace with your uploaded image\n",
        "# If file not present, this cell will show instructions\n",
        "import os\n",
        "if not os.path.exists(sample_img):\n",
        "    print('Upload an image named bus.jpg via the Colab file browser or change the path.')\n",
        "else:\n",
        "    results = model.predict(source=sample_img, show=True, conf=0.45)\n",
        "    print('Done')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37cc8165",
      "metadata": {
        "id": "37cc8165"
      },
      "source": [
        "## 4) Run on a video file (and save output)\n",
        "\n",
        "Upload a video file named `test_video.mp4` or change the path below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f55f4f1",
      "metadata": {
        "id": "4f55f4f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b52bc33-0d68-421d-dbcd-1fda72fc4731"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload test_video.mp4 or change video_path\n"
          ]
        }
      ],
      "source": [
        "# Inference on a video (will save results to runs/detect/predict)\n",
        "video_path = '/content/istockphoto-2186968774-640_adpp_is.mp4'\n",
        "import os\n",
        "if os.path.exists(video_path):\n",
        "    results = model.predict(source=video_path, conf=0.45, save=True)\n",
        "    print('Saved results to runs/detect/predict')\n",
        "else:\n",
        "    print('Upload test_video.mp4 or change video_path')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adb60ad9",
      "metadata": {
        "id": "adb60ad9"
      },
      "source": [
        "::## 5) Real-time webcam (local machine)\n",
        "\n",
        "Colab cannot display a continuous local webcam feed inside the notebook easily. For live demos on your laptop, run the following script locally (not in Colab):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e452f76",
      "metadata": {
        "id": "6e452f76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa84ee0d-d636-4078-b71f-01c491be14e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "realtime_yolo.py saved. Download it and run locally for webcam demo.\n"
          ]
        }
      ],
      "source": [
        "realtime_code = r\"\"\"from ultralytics import YOLO\n",
        "import cv2, time\n",
        "\n",
        "model = YOLO('yolov8n.pt')  # ensure the weight file is available locally or will auto-download\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "prev_time = time.time()\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    results = model(frame, conf=0.45)\n",
        "    annotated = results[0].plot()\n",
        "\n",
        "    # compute FPS\n",
        "    curr_time = time.time()\n",
        "    fps = 1.0 / (curr_time - prev_time + 1e-9)\n",
        "    prev_time = curr_time\n",
        "    cv2.putText(annotated, f'FPS: {fps:.2f}', (10,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
        "\n",
        "    cv2.imshow('Realtime YOLOv8', annotated)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\"\"\"\n",
        "\n",
        "with open('realtime_yolo.py', 'w') as f:\n",
        "    f.write(realtime_code)\n",
        "\n",
        "print('realtime_yolo.py saved. Download it and run locally for webcam demo.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "abaa7adc",
      "metadata": {
        "id": "abaa7adc"
      },
      "source": [
        "## 6) Filter detections by class and save snapshots\n",
        "\n",
        "Example code to filter for specific classes (e.g., 'person', 'car') and save frames with detections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d32adba",
      "metadata": {
        "id": "7d32adba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2919368-7c4d-422e-f697-6e862618907f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/Screenshot 2025-10-28 112928.png: 448x640 1 bus, 362.9ms\n",
            "Speed: 16.8ms preprocess, 362.9ms inference, 33.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "No person found in image.\n"
          ]
        }
      ],
      "source": [
        "# Example: filter results and save frames with a 'person' detection\n",
        "from pathlib import Path\n",
        "Path('snapshots').mkdir(exist_ok=True)\n",
        "import cv2, numpy as np, os\n",
        "\n",
        "# process a single image and save if person detected\n",
        "img_path = '/content/Screenshot 2025-10-28 112928.png'  # replace with your uploaded image\n",
        "if os.path.exists(img_path):\n",
        "    res = model(img_path, conf=0.45)\n",
        "    boxes = res[0].boxes\n",
        "    found_person = False\n",
        "    for box in boxes:\n",
        "        cls = int(box.cls[0])\n",
        "        name = model.names[cls]\n",
        "        if name == 'person':\n",
        "            found_person = True\n",
        "    if found_person:\n",
        "        img = cv2.imread(img_path)\n",
        "        cv2.imwrite('snapshots/detected_person.jpg', img)\n",
        "        print('Saved snapshots/detected_person.jpg')\n",
        "    else:\n",
        "        print('No person found in image.')\n",
        "else:\n",
        "    print('Upload or provide an image at img_path to run this cell.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MfnGaO8MZ4Ou"
      },
      "id": "MfnGaO8MZ4Ou",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}